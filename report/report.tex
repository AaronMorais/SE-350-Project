\documentclass[12pt]{report}

% Packages (keep sorted)
\usepackage{
    algorithm,      % For algorithm environment
    algpseudocode,  % For pseudocode
    hyperref,       % For PDF bookmarks
    tikz,           % For state diagrams
    color,
    listings,
    graphicx
}

\definecolor{light-gray}{rgb}{0.9, 0.9, 0.9}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{
    backgroundcolor=\color{light-gray}, % Background color
    basicstyle=\footnotesize,        % the size of the fonts that are used for the code
    belowskip=1pt,
    breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
    breaklines=true,                 % sets automatic line breaking
    captionpos=b,                    % sets the caption-position to bottom
    commentstyle=\color{mygreen},    % comment style
    deletekeywords={...},            % if you want to delete keywords from the given language
    escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
    extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
    keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
    keywordstyle=\color{blue},       % keyword style
    language=C,                      % the language of the code
    morekeywords={*,...},            % if you want to add more keywords to the set
    numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
    numbersep=5pt,                   % how far the line-numbers are from the code
    numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
    showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
    showstringspaces=false,          % underline spaces within strings only
    showtabs=false,                  % show tabs within strings adding particular underscores
    stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
    stringstyle=\color{mymauve},     % string literal style
    tabsize=2,                       % sets default tabsize to 2 spaces
    title=\lstname
}


% State diagrams (i.e. I/O)
\usetikzlibrary{
    shadows,
    positioning,
}
% TODO: move these to another file.
\tikzstyle{block} = [rectangle, draw,
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw]
\tikzstyle{cloud} = [draw, rectangle, node distance=3cm,
    minimum height=2em]

% PDF bookmarks setup (keep sorted)
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
}

\begin{document}

% Info section

% TODO come up with something more creative
\title{RTX Project Report}

% TODO check names %
\author{
    Xiang, Dian\\
    20431601\\
    \texttt{dxiang@uwaterloo.ca}
    \and
    Justin McGirr\\
    20413625\\
    \texttt{jmcgirr@uwaterloo.ca}
    \and
    Adrian Cheung\\
    20421743\\
    \texttt{a32cheun@uwaterloo.ca}
    \and
    Aaron Morais\\
    20413440\\
    \texttt{aemorais@uwaterloo.ca}
}

\maketitle

\begin{abstract}
    % Using the Keil Development Environment (Keil IDE) and LPC1768 boards using
    % the ARM instruction set, an operating system was implemented with basic
    % functionality throughout this project. The operating system offers a stable
    % and succinct API, and also tries to ensure high-performance.
    % It offers a message-passing interface between processes, and allows
    % processes to release the processor to share CPU time. Additionally, we
    % implemented memory management of the on-board memory, allowing processes to
    % dynamically acquire and release memory during our operating-system's
    % runtime.
    % I/O between keyboard input and display output on a UART connection was also
    % implemented, which allows users to interact with processes on the system in
    % near real-time. Overall, this operating system offers a minimal but fast
    % API, and is easily extendible with features necessary to implement a larger
    % and more feature-complete operating system with minimal overhead.
\end{abstract}

\tableofcontents
\listofalgorithms
\listoffigures

% NOTE(sanjay): uncomment these if we add any figures or tables
% \listoftables


\part{Introduction}
% TODO INTRODUCTION

\part{Awesome RTX}
% Make sure to include pseudocode and testing, if appropriate.

\chapter{Global Variables}
\section{Description}
There are various amounts of variables used throughout the RTX. This section describes the global variables that are used to accomplish tasks in the RTX. Other global variables such as the global process IDs can be seen in the appendix TODO. There are three major sections that required global variables and data structures: memory management in the heap, scheduler, and user processes.

\section{Heap Data Structures}
The RTX provides functionality to request and release memory from the heap, which is shared and stored in the RAM of the board. There is one main data structure that stores each memory block.

\begin{lstlisting}
typedef struct HeapBlockHeader {
  int source_pid;
  int dest_pid;
  unsigned int send_time;
  struct HeapBlock* p_next;
  struct HeapBlock* p_next_usr;
} HeapBlockHeader;

#define HEAP_BLOCK_SIZE 128

typedef struct HeapBlock {
  HeapBlockHeader header;
  byte            data[HEAP_BLOCK_SIZE];
} HeapBlock;

\end{lstlisting}

The HeapBlock structure stores a header and the content of the block. When a memory is requested, users are given the data with a adjustable size of HEAP\_BLOCK\_SIZE and does not have knowledge of the header. Helper functions in the RTX turn the user block back into kernel block by adjusting the pointer of the block. Each header contains information about message passing (if the block is used for this purpose) and a pointer to the next block (for kernel memory management purposes). This global data structure is used in the following sections:
\begin{enumerate}
    \item {\bf Memory Management} - this section uses this data structure to give and receive back heap memory blocks
    \item {\bf Process Message Passing} - this section uses this data structure pass messages between processes. Message envelope are implemented as HeapBlocks.
    \item {\bf Timer I-Process} - The process uses message passing to send delayed messages.
    \item {\bf UART I-Process} - The process uses message passing to process input and output characters.
    \item {\bf CRT I-Process} - The process receives messages and passes message for terminal output.
    \item {\bf KCD Process} - The KCD uses message passing to CRT for display and user processes for processing.
\end{enumerate}


\section{Process Scheduler Data Structures}
The RTX has a fixed-priority based scheduler that acts as a uniprocessor system. Context switching is required and the following data structures are used for this purpose.

\subsection{Ready and Blocked Priority Queues}
On initialization, each in memory process is given a process control block (PCB). The PCB contains data on the process such as its process ID, stack pointer, process state, and priority that the kernel will use for scheduling. The blocked and ready priority queues of PCBs keep track of which processes are blocked and ready for execution. Each process is in one of the 5 states at all time listed in ProcessState. More details about the states can be found in section TODO. Processes that are in state PROCES\_STATE\_READY are on the ready queue. Processes in state PROCESS\_STATE\_BLOCKED are in the blocked queue. There is also an implicit queue for processes blocked on message but we won't go into that in this section.

\begin{lstlisting}
typedef enum {
  PROCESS_STATE_NEW                = 0,
  PROCESS_STATE_READY              = 1,
  PROCESS_STATE_RUNNING            = 2,
  PROCESS_STATE_BLOCKED            = 3,
  PROCESS_STATE_BLOCKED_ON_MESSAGE = 4,
} ProcessState;

typedef struct PCB {
  // Stack pointer
  U32*            sp;

  ProcessID       pid;
  ProcessState    state;
  ProcessPriority priority;

  struct PCB*     p_next;
  // Incoming messages, waiting to be processed.
  HeapBlock*      message_queue;
} PCB;

PCB* g_ready_process_priority_queue[PROCESS_PRIORITY_NUM] = {NULL};
PCB* g_blocked_process_priority_queue[PROCESS_PRIORITY_NUM];
\end{lstlisting}

PCBs and the priority queues are used in the following sections:
\begin{enumerate}
    \item {\bf Memory Management} - When a process requests memory without available memory blocks, the memory management unit must add the process to a blocked queue. When a memory block is released, the process with the highest priority in the blocked queue (if any) is moved into the ready queue. Thus, the memory management unit must have access to the PCBs, and blocked and ready queues in order to accomplish these task.
    \item {\bf Process Management} - The process management unit is the one that schedules processes and keep track of the process priorities. Ready processes are taken from the ready queue to be ran if the current process is blocked or finished its execution. The process management unit also takes care of updating the two priority queues when the priority of a process has been changed.
    \item {\bf UART Process} - The UART Process needs access to the PCB. The PCBs also contain a mailbox for messages. The UART displays any incoming messages to the terminal display. Thus, it needs to know the PCB structure in order to gain access to the mailbox.
\end{enumerate}

\subsection{Priorities}
The RTX is based on a fixed-priority scheduler with 5 user process priorities and 2 system process priorities given below. Users are given priorities PROCESS\_PRIORITY\_HIGH to PROCESS\_PRIORITY\_LOWEST. PROCESS\_PRIORITY\_NULL\_PROCESS is given to the null process and PROCESS\_PRIORITY\_SYSTEM\_PROCESS are given to critical processes such as the KCD, CRT, timer I-process, and UART I-process.

\begin{lstlisting}
typedef enum {
  PROCESS_PRIORITY_INVALID        = 0,
  PROCESS_PRIORITY_SYSTEM_PROCESS = 1,
  PROCESS_PRIORITY_HIGH           = 2,
  PROCESS_PRIORITY_MEDIUM         = 3,
  PROCESS_PRIORITY_LOW            = 4,
  PROCESS_PRIORITY_LOWEST         = 5,
  PROCESS_PRIORITY_NULL_PROCESS   = 6,
  PROCESS_PRIORITY_UNSCHEDULABLE  = 7,

  PROCESS_PRIORITY_NUM            = 8
} ProcessPriority;

typedef enum {
  USER_PROCESS_PRIORITY_HIGH           = 0,
  USER_PROCESS_PRIORITY_MEDIUM         = 1,
  USER_PROCESS_PRIORITY_LOW            = 2,
  USER_PROCESS_PRIORITY_LOWEST         = 3,

  USER_PROCESS_PRIORITY_NUM            = 4,
} UserProcessPriority;
\end{lstlisting}

This priority structure is used by the process management unit to schedule and block processes based on their priorities. The RTX provides users with UserProcessPriority while keeping an internal structure of ProcessPriority.

\subsection{Message Passing}
Message passing is a way for interprocess communication provided by the RTX. Messages are created in the form of a msgbuf structure, which includes the type and content. Some processes such as the CRT and KCD will require a certain type of message to be sent before the message can be processed correctly.

\begin{lstlisting}
typedef enum {
  MESSAGE_TYPE_KCD_KEYPRESS_EVENT       = 0,
  MESSAGE_TYPE_KCD_COMMAND_REGISTRATION = 1,
  MESSAGE_TYPE_CRT_DISPLAY_REQUEST      = 2,
  MESSAGE_TYPE_WALL_CLOCK               = 3,
  MESSAGE_TYPE_COUNT_REPORT             = 4,
  MESSAGE_TYPE_WAKEUP_10                = 5,

  MESSAGE_TYPE_NUM                      = 6,
} MessageType;

struct msgbuf {
  MessageType mtype:
  char mtext[HEAP_BLOCK_SIZE - sizeof(MessageType)];
};

\end{lstlisting}

The message passing data structure is evident in the KCD, wall clock process, and all I-processes. It can also be used in all user processes.


\chapter{Kernel API}
% TODO add a section on implementation details and run time analysis.
\section{Description}
This section describes the kernel API that is available to users in the RTX. It will only go into details of how to use each API function call and states of different scenarios. Details of the implementation can be found in section TODO or from the raw code.

\section{Memory Management}
\subsection{Description}
% TODO fill in figure blah
The RTX provides the utility of simple memory management of the heap. The main memory on the board (TODO: name the board) is divided into sections of the RTX Image, PCB data, the heap, and process stacks seen in figure blah.
*** TODO insert figure blah here ***

Board LPC17xx (TODO insert the real name) does not have the hardware to support virtual memory. Thus, a fixed memory management scheme is used with variable block sizes. The OS kernel is alway loaded into main memory. When the OS boots, a user stated number of PCBs and process stack are allocated. The OS also allocates memory for system processes such as the Keyboard Command Decoder Process (KCD) and the CRT Display Process. After allocation of PCBs and process stacks, the remaining memory is used for the heap, which is shared between all processes. This section will be focused on the memory management of the heap.

The heap is further divided into a variable number of blocks. Each block contains a header (HeapBlockHeader) and 128 bytes of data. Depending on the number of user and system processes, the number of available heap memory will vary. The size of the data can vary from 128 bytes but must be set at compile time. The OS supports two kernel calls that gives access to these memory blocks.

\subsection{Requesting Memory}
\label{sec:request_memory}
\begin{lstlisting}
void *request_memory_block();
\end{lstlisting}
\par The first functionality supported by the OS is the ability to request memory. This call gives back a pointer to a memory block in the heap. The size of the memory block is defined by the constant HEAP\_BLOCK\_SIZE, which defaults to 128 bytes. These blocks are used for storing local variables or as envelopes for interprocess communication (described in section TODO). The user must cast the memory block to the proper type for his or her own use. An example of the usage is provided below, which stores the numbers 0-31 in an array of size 32.
\begin{lstlisting}
void user_process() {
    int size = 32;

    int* array = (int*)request_memory_block();

    for( int i = 0; i < size; i++ ) {
        array[i] = i;
    }

    // ...

    release_memory_block( (void*)array );
}
\end{lstlisting}
% TODO maybe put a caption here CODE1

\par All processes will share the same heap memory pool. Thus, this primitive will block the process if the OS does not have anymore memory blocks to give out at the time, thus effecting the execution of the process. In that case, it will only be unblocked there is a new memory block available and if it has the highest priority on the list of processes waiting for a memory block. When using the memory block, the user must be aware of writing past the heap block size. The OS does not check for segmentation faulting. Thus, undefined behavior may occur. Also, the user must remember to release the memory block or memory leakage will occur.

\par Requesting memory is reliant on calls to the heap to find an available memory block to allocate. The heap keeps a list of the status of each memory block to determine whether or not a block of memory can be requested. The following is the implementation used by the heap:
\begin{algorithmic}
  \Function{FindFreeBlock}{}
    \For{$i = 0$ to $TotalNumberOfBlocks$}
      \If{FreeSpaceBitmap[i] is a free block}
        \State return i
      \EndIf
    \EndFor
  \State return not found
  \EndFunction
\end{algorithmic}

The lookup time of the FreeSpaceBitmap is O(1) as it is a simple array lookup and a boolean evaluation. Finding a free block has its dependencies on the total number of blocks. The best case for requesting memory is O(1) when the first block in the heap is free. Since this is a linear search, on average the complexity is O(n) where n is the total number of blocks.

\bigskip

\subsection{Releasing Memory}
\begin{lstlisting}
int release_memory_block(void *memory_block);
\end{lstlisting}

\par The second functionality supported by the OS is the ability to release memory. This is a non-blocking call that returns the memory block back to the OS. This should be called when a message is received and not passed on or when the process is done using the memory block. If any process is blocked on memory, it will be unblocked and put to the ready queue. If the current process has lower priority than the unblocked process, then the current process will be preempted and the higher priority process will be executed instead. An example of this can be seen in figure CODE1 TODO on line 13.

\par In order to release the memory, release\_memory\_block will need to rely on the implementation of the heap. As stated in \ref{sec:request_memory}, the heap keeps a list of all available memory blocks. In order to release a memory block, the heap will set that block in the list as a free block. Releasing the block thus has O(1) complexity as it only relies on an array lookup. The implementation is as follows:
\begin{algorithmic}
  \Function{ReleaseMemory}{MemoryBlock}
    \State FreeSpaceBitmap[position of MemoryBlock] \gets true
  \EndFunction
\end{algorithmic}

\bigskip

\section{Processor Management}
\begin{lstlisting}
int release_processor();
\end{lstlisting}

\par The OS manages processes as though it is on a uniprocessor. A priority based scheme with context switching is used for scheduling processes. A process can voluntarily release the processor to the OS at any time during its execution. If there are errors in the call, it will return an error without releasing the processor to the OS. If there are no errors and the invoking process is ready to execute, it is put to the end of the ready queue of its priority. If there are no other processes of equal or higher priority, the process will be chosen to execute again. However, if there is, another process may be chosen for execution. Below is an example which prints an increasing number and releases the processor at every turn.

\begin{lstlisting}
void user_process() {
    static num = 0;
    while(1) {
        print(num++);
        release_processor();
    }
}
\end{lstlisting}

\section{Interprocess Communication}
\par Apart from heap memory, processes do not share information. Thus, communication between processes is done through message-based interprocess communication (IPC). Details of the internal layout of process mailboxes can be found in section TODO. The RTX gives three primitives to carry out this task, one for sending, one for delayed sending, and one for receiving.

\subsection{Send Messages}
\label{sec:send_message}
\begin{lstlisting}
int send_message(int process_id, void *message_envelope);
\end{lstlisting}

\par A process can compose a message envelope to be sent to another process. Memory for envelope message must be requested from the RTX using the request\_memory() routine. The envelope consists of a type (mtype) and the message data (mtext) which must be filled in as seen below. The predefined message types are used for the KCD, CRT, and Wall Clock process, which are built into the RTX (see section TODO for more information). The message data has a predefined size which is a MessageType smaller than the HEAP\_BLOCK\_SIZE. Thus, any message that are longer will exhibit undefined behavior. The process ID of the receiving process must also be known ahead of time in order to use send\_message.
\newline
\begin{lstlisting}
typedef enum {
    MESSAGE_TYPE_KCD_KEYPRESS_EVENT       = 0,
    MESSAGE_TYPE_KCD_COMMAND_REGISTRATION = 1,
    MESSAGE_TYPE_CRT_DISPLAY_REQUEST      = 2,
    MESSAGE_TYPE_WALL_CLOCK               = 3,
    MESSAGE_TYPE_USER_DEFINED             = 4,

    MESSAGE_TYPE_NUM                      = 5,
} MessageType;

struct msgbuf {
    MessageType mtype;
    char mtext[HEAP_BLOCK_SIZE - sizeof(MessageType)];
};
\end{lstlisting}
% TODO (Justin) make sure that's okay for the mtext and type:P
\par The primitive returns a status which validates the, message, receiver process ID, and ready queue. User processes is allowed to send a message to any user processes or system processes such as the KCD. If the receiving process is currently blocked on receiving message, this call will add the message to the process' message box and put it back on the message queue. The current process continues to execute unless the receiving process has a higher priority. In that case, the current process will be preempted and put to the back of the ready queue. Thus, this primitive may effect the execution of the process.

\par In order to keep track of messages that have been sent, the messages are stored in a queue, specifically a linked list. Messages are added to the end of the linked list resulting in an O(n) insertion complexity. It is possible to have this run in O(1) time by having the inserting take place at the front of the linked list, however this is a trade-off for receiving messages. In the current implementation, received messages will be taken from the front of the linked list having O(1) complexity. If the change was to be made to optimize sending messages, then this would slow down receiving messages to O(n).
\newline
\subsection{Receive Messages}
\label{sec:receive_message}
% TODO put labels on sections so we can reference them throughout without worrying about changing numbers

\begin{lstlisting}
void *receive_message(int *sender_id);
\end{lstlisting}
\par A process can use this primitive to receive messages from other processes. Unless the sender\_id is NULL, the sender of the message will be written to the sender\_id parameter. The current process will check its mailbox for any incoming messages. If there are no messages in its mailbox, the routine will block the process and select another process for execution. Execution of the process will occur again if a message is sent from another process and this process has the highest priority in the ready queue. The message\_envelope are heap memory underneath. Thus, it is required that unless the process passes the message onto another process, the final receiving process must release the message\_envelope block after its usage. An example of send\_message and receive\_message is shown below.

\begin{lstlisting}
void process_send() {
    while(1) {
        // Request one block for process_receive to use
        struct msgbuf* message_envelope
            = (struct msgbuf*)request_memory_block();
        message_envelope->mtype = MESSAGE_TYPE_USER_DEFINED_1;
        strcpy(message_envelope->mtext, "process message");
        send_message(PROCESS_RECEIVE_ID, message_envelope);

        // Send another block for process_receive to send to CRT
        struct msgbuf* message_envelope
            = (struct msgbuf*)request_memory_block();
        message_envelope->mtype = MESSAGE_TYPE_USER_DEFINED_2;
        strcpy(message_envelope->mtext, "print this");
        send_message(PROCESS_RECEIVE_ID, message_envelope);
    }
}

void process_receive() {
    while(1) {
        struct msgbuf* message
            = (struct msgbuf*)receive_message(NULL);
        if( message->mtype = MESSAGE_TYPE_USER_DEFINED_2 ) {
            // Send to CRT for printing; do not release memory
            message->mtype = MESSAGE_TYPE_CRT_DISPLAY_REQUEST;
            send_message(PROCESS_ID_CRT, message);
        } else {
            // Do something with the message then release it
            release_memory_block( (void*)message );
        }
    }
}
\end{lstlisting}

\subsection{Delayed Messages}
\begin{lstlisting}
int delayed_send(int process_id, void *message_envelope, int delay);
\end{lstlisting}

\par This primitive is very similar to the primitive of send\_message in section \ref{sec:send_message} with the addition of a delay. Instead of sending the message immediately, the message will be sent delay number of milliseconds. The message\_envelope is constructed in the same way. The process\_id will be the receiving process. The execution of the process may be preempted after a the delay period if the receiving process was blocked on receive\_message and has a higher priority.

\section{Process Priority}
\par The RTX schedules processes based on a fixed priority scheme. Thus, the RTX provides the utility to change priorities and to get the process priority of any user processes.

\subsection{Set Process Priority}
\label{sec:set_process_priority}
\begin{lstlisting}
int set_process_priority(int process_id, int priority);
\end{lstlisting}

This primitive allows user processes to set the priorities of other user processes. User processes are not allowed to set the priorities of any system processes. System processes, however, are allowed to set the priorities of other system or i-processes. The primitive validates if the current process is allowed to set the priority of the process with process\_id and whether it's a valid process\_id. It also checks the validity of the priority. An error status of RTX\_ERR is given back if the validation does not pass. If properly set, a status of RTX\_OK is returned. The caller of this primitive is not blocked but can be preempted if the priority of the set process is higher. Otherwise, the process continues to execute. An example usage is shown in section \ref{sec:get_process_priority}

\bigskip

\subsection{Get Process Priority}
\label{sec:get_process_priority}
\begin{lstlisting}
int get_process_priority(int process_id);
\end{lstlisting}
Given a process\_id, this primitive gives back the priority of any processes including any system or i-processes to a user process. A invalid process\_id will result in a RTX\_ERR status. Otherwise, a RTX\_OK is returned to the caller. An example usage of both get and set process priority is shown below.

\begin{lstlisting}
// Assume this process has a process ID of 3
// and there is another user process with ID of 1
void user_process() {
    int process_priority_3 = get_process_priority(3);
    if( process_priority_3 == USER_PROCESS_PRIORITY_MEDIUM ) {
        // Make process 1 have a higher priority
        // This call will preempt
        int status = set_process_priority(
                        1, USER_PROCESS_PRIORITY_HIGH );
        if( status == RTX_ERR ) {
            release_processor();
        }
    }
}
\end{lstlisting}


\chapter{Interrupts and Their Handler and Processes}

\section{Description}

\section{UART}

\section{TIMER}


% TODO Make sure to include pseudo-code and testing, if appropriate.

\chapter{System and User Processes}

\section{System Processes}
\subsection{Description}
The RTX consists of system processes that sit on top of the kernel. These system processes usually have higher priority than user processes because they carry out tasks for the OS that the kernel cannot do otherwise. System processes in this RTX includes the null process, and I/O processes.

\subsection{Null Process}
The design of the RTX requires that a process should always be executing. Thus, if there are no user or other system processes, the null process executes. The only job of the null process is to keep the processor running. It has the lowest priority of any process using the RTX. If any process is added into the ready queue during the execution of this process, a preemption will occur and the new process will take control of the processor. The final implementation follows the following form.

 \begin{algorithmic}
  \Function{null\_process}{}
    \While{true}
    \EndWhile
  \EndFunction
 \end{algorithmic}

\subsection{CRT Display Process}
\label{sec:crt_process}
% TODO make footnotes for details
The RTX supports output to terminal display. CRT is a system process that the RTX uses to accomplish the task of display. The CRT process depends on the UART I-Process (details of the UART can be found in section TODO). The CRT is implemented using the following algorithm.

\begin{algorithmic}
  \Function{crt\_process}{}
    \While{true}
        \State message = \Call{receive\_message}{NULL}
        \If{message is not a CRT display request}
            \State continue
        \EndIf
        \State \Call{send\_message}{PROCESS\_ID\_UART, message}
        \State Set interrupt bits
    \EndWhile
  \EndFunction
 \end{algorithmic}

 The CRT display process accepts message requests from any process of type MESSAGE\_TYPE\_CRT\_DISPLAY\_REQUEST. This tells the CRT to send the message for display to the UART I-process, which interacts with the hardware registers to output to terminal. Since the UART process is an interrupt process, the interrupt bit must be set in order for the process to run. Thus, after sending the message to UART's mailbox, the CRT process enables the interrupt bits for the I-process to trigger. The UART I-process passes the message character by character to the hardware to display to the terminal.

\subsection{Keyboard Command Decoder Process}
\label{sec:kcd_process}
The RTX provides functionality to forward user input commands to a particular process. The keyboard command decoder process (KCD) handles two tasks: giving input to the CRT for terminal display and forwarding certain inputs to different processes for further processing. For the first task, all keyboard inputs are filtered by the KCD. The UART I-process is called when a key is first pressed. The UART I-process (explained further in section TODO) then passes a message to the KCD telling of type key press. In the first case, the KCD will take this message and pass it on to the CRT for terminal display.

In the latter case, processes can register a command with the KCD. Each command registration consists of a single capital letter of the alphabet. If a command is taken, the KCD will not register the command and exit with an error. After a valid command has been registered, user input with the pattern "\%" followed by a upper case character will be parsed by the KCD. If user types in "\%" followed by a registered character, the KCD will buffer the input until the user presses the return key. In that scenario, the KCD will pass it onto the registered process. The following algorithm of the KCD explains this in more detail.

\begin{algorithmic}
    \Function{process\_input}{message}
        \If{ There a "\%" character in the buffer }
            \If{message.Content is a command character}
                \State add to buffer
            \Else
                \State clear buffer
            \EndIf
        \ElsIf{ message.Content is "\%" }
            \State add to buffer
        \ElsIf{ message.Content is enter and buffer is not empty}
            \State send buffer to registered command
        \EndIf
        \State Send message to CRT to display

    \EndFunction

    \bigskip

    \Function{process\_register}{message}
        \If{ message.Command has not been taken}
            \State register message.Command
        \Else
            \State error
        \EndIf
    \EndFunction

    \bigskip

    \Function{kcd\_process}{}
        \State initialization
        \While{true}
            \State message = \Call{receive\_message}{NULL}
            \If{message type is key press input}
                \State \Call{process\_input}{message}
            \ElsIf {message type is command registration}
                \State \Call{process\_register}{message}
            \EndIf
        \EndWhile
    \EndFunction
\end{algorithmic}

An example of this usage is the wall clock process (described in more detail in section \ref{sec:wall_clock_process}). The wall clock process registers the character 'W' as a command. The registration will be done by passing a message to the KCD of command registration type. This message is received by the KCD. If the 'W' command has not been registered, it becomes registered by the wall clock process. Meanwhile, the user types in random characters. Any character that is not '\%' is passed by the KCD to the CRT for display. Once a '\%' is received, the KCD checks the next character to see if it's a registered command. If its not a registered command, the KCD clears the buffer and starts at the beginning. If it is a registered command, the KCD keeps a buffer of all the input characters. This buffer fills with data and is sent to the wall clock process for processing after the user presses enter. The buffer is only 20 characters long. Thus, any data for a process after 20 characters will not be sent to the registered process on enter.



\section{User Processes}
\label{sec:user_processes}

\subsection{Wall Clock Process}
\label{sec:wall_clock_process}

\subsection{`funProcess'}

\subsection{`schizophrenicProcess'}

\subsection{`fibProcess'}

\subsection{`memoryMuncherProcess'}

\subsection{`releaseProcess'}



\chapter{Initialization}

\section{Description}

\section{Memory Layout}

\section{Process Mailbox}



\chapter{Major Design Changes}

\section{Description}

\section{Heap}

\section{Scheduler}

\section{What We Learned}

\part{Testing and Analysis}

\chapter{Testing}

\section{Description}

\section{Theoretical Analysis}

\section{Measurements}

\chapter{Timing Analysis}

\section{Requesting and Releasing Memory}

\par All data used and processed data can be found in the Appendix in \ref{appendix:raw_data}

\subsection{Single Request Single Release}
\label{sec:single_request_single_release}
In the first analysis, the request\_memory and release\_memory methods were timed. Single request, single release means that a single memory block was requested and the time taken was recorded. Similarly for releasing a memory block. By doing so we are able to keep the heap in the same state, eliminating the effects of cumulative memory requests (which will be tested in section \ref{sec:cumulative_memory_requests}). The method to time this is shown in the following algorithm. Data was collected across 5 machines, with 1000 calls to each function.

\begin{algorithmic}
  \Function{Single\_Request\_Single\_Release}{}
    \For{$i = 0$ to $1000$}
      \State RequestStartTime[i] \gets Curent Time
      \State memoryBlock \gets  \Call{request\_memory\_block}{}
      \State RequestEndTime[i] \gets Curent Time
      \State ReleaseStartTime[i] \gets Curent Time
      \State \Call{release\_memory\_block}{memoryBlock}
      \State ReleaseEndTime[i] \gets Curent Time
    \EndFor
  \EndFunction
\end{algorithmic}

Based on the analysis, the mean run time for release memory is 405.44ns. The standard error (marked in the green mean diamonds on the figure) is very small, giving a 95\% confidence interval ranging from [404.99, 405.84] to [405.1, 405.95]. The F ratio is incredibly small (0.0474), meaning that there is little to no variance among the different machines and as such it can be concluded that the hardware does not greatly affect the performance of the method.

\begin{figure}[h!]
  \centering
    \includegraphics{SRSRRequestMemory.png}
  \caption{Request Memory over 5 machines}
\end{figure}

The results of releasing memory are very similar to that of requesting memory. The mean time taken to release memory is 1229.237ns. The variations among different machines were very small, giving an F Ratio of 0.0328. This shows that the performance is consistent across different hardware. The performance was as well consistent within itself, the fastest machine had a 95\% confidence interval of [1228.5, 1229.9], and for the slowest [1228.6, 1230.0]. Releasing memory takes on average a little under three times as long as requesting memory   

\begin{figure}[h!]
  \centering
    \includegraphics{SRSRReleaseMemory.png}
  \caption{Release Memory over 5 machines}
\end{figure}

\subsection{Cumulative Memory Requests}
\label{sec:cumulative_memory_requests}

\par The cumulative memory requests condition had 50 memory blocks requested and then subsequently released. This differs from experiment in \ref{sec:single_request_single_release} where the requested memory blocks do not accumulate. The purpose of this experiment is to see the effect of depleting resources on run time. Once again, trials were taken over 5 machines, however, each machine showed the same performance. To acheive this, the following two method calls were made.

\begin{algorithmic}
  \Function{Cumulative\_Request}{}
    \For{$i = 0$ to $50$}
      \State RequestStartTime[i] \gets Curent Time
      \State memoryBlock \gets  \Call{request\_memory\_block}{}
      \State RequestEndTime[i] \gets Curent Time
    \EndFor
  \EndFunction
\end{algorithmic}

\begin{algorithmic}
  \Function{Cumulative\_Release}{}
    \For{$i = 0$ to $50$}
      \State ReleaseStartTime[i] \gets Curent Time
      \State memoryBlock \gets  \Call{release\_memory\_block}{}
      \State ReleaseEndTime[i] \gets Curent Time
    \EndFor
  \EndFunction
\end{algorithmic}

\par Consistent with the Single Request, Single Release experiment, the first memory block requested took 1229ns. A linear trend line is overlaid on top showing an R2 value of 1 (a perfect trend). The trend shows that for each additional memory block requested, the run time increase by 17ns. This linear trend is in accordance with the implementation of the request memory method which has O(n) complexity described in \ref{sec:request_memory}. 

\begin{figure}[h!]
  \centering
    \includegraphics{RequestMemory.png}
  \caption{Release Memory over 5 machines}
\end{figure}

\section{Sending and Receiving Messages}
\subsection{Single Send, Single Receive}
\label{sec:single_send_single_receive}

In this experiment, the send\_message and receive\_message methods were timed. A single message was sent and the time taken was recorded. Similarly, the time taken to receive that message was timed, specifically the time for the function call and not the delay between the time the message was sent and the time the message was received. By doing so we are able to eliminate the effects of having inconsisent memory available (that will be tested in the following experiment). To achieve this, two user processes were defined, the first sends a message of a fixed size then releases the processor, the second would then receive that message and again release the processor. This process would then repeat a total of 498 times. Data was collected across 5 machines, with 498 calls to each function.

\begin{figure}[h!]
  \centering
    \includegraphics{SSSRSend.png}
    \includegraphics{SSSRReceive.png}
  \caption{Top: Sending messages; Bottom: Receiving messages}
\end{figure}

In this single send, single receive condition, a total of 2490 trials were taken, and the data showed no variation for either sending messages or receiving messages. The mean run time of sending a message is 399ns. Due to the lack of variation on or between each machine this is also the value of the lower and upper bound of the 95\% confidence interval. The same applies for receiving the message, which is twice as fast at 182ns. 

\subsection{Cumulative Message Sending}
\label{sec:cumulative_message_sending}

The cumulative message sending condition, as the name implies, had messages accumulate before any were received. The purpose of this is to the see the relation between the number of messages sent (and not yet received) with the time it takes to send a new message. In order to test this, 50 messages were sent from within a single user processes. Once finished, another process would take over and receive those 50 messages. The results from 5 different machines are displayed in the Figure.
\begin{figure}[h!]
  \centering
    \includegraphics{SendMessage.png}
  \caption{Cumulative message sending}
\end{figure}

Similar to the single send, single receive condition in \ref{sec:single_send_single_receive}, the results were the same across all machines. A linear trend line is superimposed onto the results. The trend displayed has an R2 value of 1 showing that this linear trend is very significant. This correlates with the expected O(n) complexity of the send method described in \ref{sec:send_message}. The trend shows an increase of 11ns per additional message sent. 

The message receiving process of this experiment was also measured. For all 250 messages received, the time taken was consistent at 182ns. This is as well expected due to the O(1) complexity of the receive message method describe in \ref{sec:receive_message}.

\subsection{Effects of Message Length}
\label{sec:message_length}
Another factor that was tested is the length of the message being sent. Depending on the implementation for the kernel it is possible that in some cases a longer message will take longer to send or receive. To test this, messages were continuously sent and received in the same manner as the single send, single receive condition in \ref{sec:single_send_single_receive} with the addition of an accumulating message (ie the first message sent was “a”, the second message “aa” and so forth).  This was tested up until a message of 50 characters was sent. As shown in the two figures, the message length had no effect on the time taken to send or receive messages.

\begin{figure}[h!]
  \centering
    \includegraphics{MessageLength.png}
  \caption{Sending messages with variable message length}
\end{figure}


\appendix
\chapter{Raw Measurement Data}
\label{appendix:raw_data}

\section{Data Analysis For Single Request Single Release}

\subsection{Request}
Summary of Fit
\newline
\begin{tabular}{l | l}
  Rsquare&2.63E-05 \\
  Adj Rsquare&-0.00077 \\
  Root Mean Square Error&11.43196 \\
  Mean of Response&1229.237 \\
  Observations (or Sum Wgts)&5000 \\
\end{tabular}
\newline

Analysis of Variance
\newline
\begin{tabular}{l | l | l | l | l | l}
Source&DF&Sum of Square&Mean Square&F Ratio&Prob > F \\
\hline
Machine&4&17.14&4.285&0.0328&0.9979 \\
Error&4995&652795.5&130.69&-&- \\ 
C. Total&4999&652812.7&-&-&- \\      
\end{tabular}
\newline

Means of Oneway Anova
\newline
\begin{tabular}{l | l | l | l | l | l}
Machine&Number&Mean&Std Error&Lower 95\%&Upper 95\% \\
\hline
16769&1000&1229.29&0.36151&1228.6&1230 \\
16773&1000&1229.29&0.36151&1228.6&1230 \\
16781&1000&1229.17&0.36151&1228.5&1229.9 \\
16782&1000&1229.17&0.36151&1228.5&1229.9 \\
16783&1000&1229.27&0.36151&1228.6&1230 \\
\end{tabular}
\newline

Means and Std Deviations
\newline
\begin{tabular}{l | l | l | l | l | l | l}
Machine&Number&Mean&Std Dev&Std Err Mean&Lower 95\%&Upper 95\% \\
\hline
16769&1000&1229.29&11.7342&0.37107&1228.6&1230 \\
16773&1000&1229.29&11.7342&0.37107&1228.6&1230 \\
16781&1000&1229.17&11.0616&0.3498&1228.5&1229.9 \\
16782&1000&1229.17&11.0616&0.3498&1228.5&1229.9 \\
16783&1000&1229.27&11.5476&0.36517&1228.6&1230 \\
\end{tabular}
\newline

\subsection{Release}
Summary of Fit
\newline
\begin{tabular}{l | l}
  Rsquare&3.79E-05 \\
  Adj Rsquare&-0.00076 \\
  Root Mean Square Error&6.8087 \\
  Mean of Response&405.4416 \\
  Observations (or Sum Wgts)&5000 \\
\end{tabular}
\newline
  \newline

Analysis of Variance
\newline
\begin{tabular}{l | l | l | l | l | l}
  Source&DF&Sum of Squares&Mean Square&F Ratio&Prob > F \\
  \hline
  Machine&4&8.79&2.1968&0.0474&0.9958 \\
  Error&4995&231560.2&46.3584&-&- \\
  C. Total&4999&231569&-&-&- \\
\end{tabular}
\newline

Means for Oneway Anova
\newline
\begin{tabular}{l | l | l | l | l | l}
  Machine&Number of Trials&Mean&Std Error&Lower 95\%&Upper 95\% \\
  \hline
  16769&1000&405.416&0.21531&404.99&405.84 \\
  16773&1000&405.416&0.21531&404.99&405.84 \\
  16781&1000&405.436&0.21531&405.01&405.86 \\
  16782&1000&405.416&0.21531&404.99&405.84 \\
  16783&1000&405.524&0.21531&405.10&405.95 \\
\end{tabular}
\newline

Means And Std Deviations
\newline
\begin{tabular}{l | l | l | l | l | l |l}
  Machine&Number&Mean&Std Dev&Std Err Mean&Lower 95\%&Upper 95\% \\
  \hline
  16769&1000&405.416&6.56765&0.20769&405.01&405.82 \\
  16773&1000&405.416&6.56765&0.20769&405.01&405.82 \\ 
  16781&1000&405.436&6.90519&0.21836&405.01&405.86 \\
  16782&1000&405.416&6.56765&0.20769&405.01&405.82 \\
  16783&1000&405.524&7.39649&0.23390&405.07&405.98 \\
\end{tabular}
\newline

\section{Data Analysis for Single Send Single Receive}
\subsection{Send}
Summary of Fit
\newline
\begin{tabular}{l | l}
  Rsquare&- \\
  Adj Rsquare&- \\
  Root Mean Square Error&0 \\
  Mean of Response&399 \\
  Observations (or Sum Wgts)&2490 \\
\end{tabular}
\newline

Analysis of Variance
\newline
\begin{tabular}{l | l | l | l | l | l}
Source&DF&Sum of Square&Mean Square&F Ratio&Prob > F \\
\hline
Machine&4&0&0&-&- \\
Error&2485&0&0&-&- \\ 
C. Total&2489&0&-&-&- \\      
\end{tabular}
\newline

Means of Oneway Anova
\newline
\begin{tabular}{l | l | l | l | l | l}
Machine&Number&Mean&Std Error&Lower 95\%&Upper 95\% \\
\hline
16769&498&399&0&399&399 \\
16773&498&399&0&399&399 \\
16781&498&399&0&399&399 \\
16782&498&399&0&399&399 \\
16783&498&399&0&399&399 \\
\end{tabular}
\newline

Means and Std Deviations
\newline
\begin{tabular}{l | l | l | l | l | l | l}
Machine&Number&Mean&Std Dev&Std Err Mean&Lower 95\%&Upper 95\% \\
\hline
16769&498&399&0&0&399&399 \\
16773&498&399&0&0&399&399 \\
16781&498&399&0&0&399&399 \\
16782&498&399&0&0&399&399 \\
16783&498&399&0&0&399&399 \\
\end{tabular}
\newline

\subsection{Receive}
Summary of Fit
\newline
\begin{tabular}{l | l}
  Rsquare&- \\
  Adj Rsquare&- \\
  Root Mean Square Error&0 \\
  Mean of Response&182 \\
  Observations (or Sum Wgts)&2490 \\
\end{tabular}
\newline

Analysis of Variance
\newline
\begin{tabular}{l | l | l | l | l | l}
Source&DF&Sum of Square&Mean Square&F Ratio&Prob > F \\
\hline
Machine&4&0&0&-&- \\
Error&2485&0&0&-&- \\ 
C. Total&2489&0&-&-&- \\      
\end{tabular}
\newline

Means of Oneway Anova
\newline
\begin{tabular}{l | l | l | l | l | l}
Machine&Number&Mean&Std Error&Lower 95\%&Upper 95\% \\
\hline
16769&498&182&0&182&182 \\
16773&498&182&0&182&182 \\
16781&498&182&0&182&182 \\
16782&498&182&0&182&182 \\
16783&498&182&0&182&182 \\
\end{tabular}
\newline

Means and Std Deviations
\newline
\begin{tabular}{l | l | l | l | l | l | l}
Machine&Number&Mean&Std Dev&Std Err Mean&Lower 95\%&Upper 95\% \\
\hline
16769&498&182&0&0&182&182 \\
16773&498&182&0&0&182&182 \\
16781&498&182&0&0&182&182 \\
16782&498&182&0&0&182&182 \\
16783&498&182&0&0&182&182 \\
\end{tabular}
\newline

\end{document}